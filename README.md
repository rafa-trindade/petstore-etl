# ğŸ¾ petstore-transform-load

Projeto responsÃ¡vel pela **transformaÃ§Ã£o e carga** de dados coletados pelo `petstore-scraping`.
Esta etapa compÃµe as camadas **Silver e Gold** da arquitetura de dados, realizando **limpeza, padronizaÃ§Ã£o, enriquecimento e carga no banco de dados**.

---

## ğŸ“Œ DescriÃ§Ã£o

O `petstore-transform-load` consome os dados brutos (camada Bronze) gerados pelo `petstore-scraping` e realiza os seguintes processos:

* **Silver:** limpeza, padronizaÃ§Ã£o e enriquecimento dos dados, incluindo preenchimento de endereÃ§os e coordenadas geogrÃ¡ficas.
* **Gold:** integraÃ§Ã£o final dos dados prontos para anÃ¡lise, estruturados e carregados no banco de dados.

Os arquivos resultantes podem ser consumidos pelo repositÃ³rio `petstore-bi` para anÃ¡lises e dashboards.

---

## ğŸ“Š Estrutura dos dados

As principais colunas tratadas sÃ£o:

| empresa | nome | logradouro | bairro | cidade | estado | cep | latitude | longitude |
| ------- | ---- | ---------- | ------ | ------ | ------ | --- | -------- | --------- |

---

## ğŸ§© Fluxo de Dados

```mermaid
graph TD
    A[petstore-scraping<br>Bronze] --> B[Silver<br>Limpeza e padronizaÃ§Ã£o]
    B --> C[Gold<br>IntegraÃ§Ã£o e carga no Banco de Dados]
    C --> D[petstore-bi<br>BI e dashboards]
```

---

## ğŸŒ API de GeolocalizaÃ§Ã£o

O projeto utiliza a API **Nominatim (OpenStreetMap)** para obter informaÃ§Ãµes de latitude, longitude e tratamento de dados faltantes.

---

## âš™ï¸ Tecnologias e bibliotecas

* [**pandas**](https://pypi.org/project/pandas/) â†’ manipulaÃ§Ã£o e estruturaÃ§Ã£o de dados tabulares
* [**brazilcep**](https://pypi.org/project/brazilcep/) â†’ padronizaÃ§Ã£o de logradouros, bairros, cidade e estado
* [**requests**](https://pypi.org/project/requests/) â†’ chamadas HTTP para APIs externas
* [**time**](https://docs.python.org/3/library/time.html) â†’ controle de pausas entre requisiÃ§Ãµes

---

## ğŸš€ PossÃ­veis usos

* Preencher automaticamente CEPs, endereÃ§os e coordenadas de lojas.
* Gerar datasets prontos para anÃ¡lise geogrÃ¡fica e regional.
* Alimentar dashboards e pipelines de BI.
